{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews.dropna()\n",
    "reviews = reviews.drop(['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator',\n",
    "                        'Score','Time'], 1)\n",
    "reviews = reviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.Text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = reviews[reviews.Summary.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews # 712\n",
      "My husband (who, being Mexican, is very picky about his tortilla chips) and I absolutely love these!  The texture is light and crispy, rather than thick and crunchy. He actually usually prefers a very hearty, cruncy chip (Like El Ranchero), but the flavor of these is so fantastic that we're both thilled with them. The bean, rice and corn base makes them incredibly flavorful, and they have a touch of onion and garlic in addition to that. We go through an embarrassing amount of them.  I never, ever like plain chips, but these I can eat without anything else, although they're particularly amazing with a fresh salsa.  I highly recommend these!\n",
      "Perfect tortilla chip goodness!\n",
      "\n",
      "\n",
      "Reviews # 713\n",
      "<a href=\"http://www.amazon.com/gp/product/B000GWLUGU\">Plocky's Tortilla Chips, Red Beans 'N Rice, 7 Ounce Bag (Pack of 12)</a>  I first tasted these chips while visiting relatives in KY.  They are not available where I live, so I ordered them from Amazon.  WOW!  My friends and family are all addicted to them.  The spicy flavor grabs you at the first bite.  Once a bag is open, it is gone!\n",
      "These chips are addictive!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysing some of the reviews\n",
    "for i in range(712,714):\n",
    "    print('Reviews #',i)\n",
    "    print(reviews.Text[i])\n",
    "    print(reviews.Summary[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some contraction to expansion\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text,remove_stopwords=False):\n",
    "    \n",
    "    text = text.lower()\n",
    "    clean_text = []\n",
    "    for word in text.split():\n",
    "        if word in contractions:\n",
    "            clean_text.append(contractions[word])\n",
    "        else:\n",
    "            clean_text.append(word)\n",
    "    text = \" \".join(clean_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br', ' ', text)\n",
    "    text = re.sub(r'/>', ' ', text)\n",
    "    text = re.sub(r'>', ' ', text)\n",
    "    text = re.sub(r'<', ' ', text)\n",
    "    text = re.sub(r'`', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<a href=\"http://www.amazon.com/gp/product/B000GWLUGU\">Plocky\\'s Tortilla Chips, Red Beans \\'N Rice, 7 Ounce Bag (Pack of 12)</a>  I first tasted these chips while visiting relatives in KY.  They are not available where I live, so I ordered them from Amazon.  WOW!  My friends and family are all addicted to them.  The spicy flavor grabs you at the first bite.  Once a bag is open, it is gone!'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-4f93a75b8050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m713\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "clean_text(str(reviews.Text[713]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_summary = [clean_text(summary) for summary in reviews.Summary]\n",
    "clean_text = [clean_text(text) for text in reviews.Text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(texts,summarys):\n",
    "    tokens = []\n",
    "    for text in texts:\n",
    "        tokens.extend(text.split())\n",
    "    for summary in summarys:\n",
    "        tokens.extend(summary.split())\n",
    "    return Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = build_vocabulary(clean_text,clean_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 126931\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Vocabulary:\", len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding \n",
    "#### Using pre-trained Conceptnet Numberbatch's Embeddings (https://github.com/commonsense/conceptnet-numberbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 417195\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 300\n",
    "embeddings = {}\n",
    "with open('embeddings/numberbatch-en-17.06.txt',encoding='utf-8') as em:\n",
    "    for embed in em:\n",
    "        em_line = embed.split(' ')\n",
    "        word = em_line[0]\n",
    "        embedding = np.array(em_line[1:])\n",
    "        embeddings[word] = embedding\n",
    "print('Word embeddings:', len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing word count :  3609\n"
     ]
    }
   ],
   "source": [
    "# Count no. of words not in Embeddings\n",
    "threshold = 20 # Discard the words appearing less then 20 times.\n",
    "missing_word_count = 0\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] >= 20 and word not in embeddings:\n",
    "        missing_word_count += 1\n",
    "\n",
    "print(\"Missing word count : \", missing_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of New Vocabulary: 59213\n",
      "Percent of actual words used :  46.64975459107704\n"
     ]
    }
   ],
   "source": [
    "# remove words having count less than threshold\n",
    "new_vocab = {word:count for word,count in vocab.items() if count >= threshold or word in embeddings}\n",
    "\n",
    "print(\"Size of New Vocabulary:\", len(new_vocab))\n",
    "print(\"Percent of actual words used : \",(len(new_vocab)/len(vocab) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_to_int = {}\n",
    "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]\n",
    "for i,code in enumerate(codes):\n",
    "    vocab_to_int[code] = i\n",
    "\n",
    "for i,word in enumerate(new_vocab.keys(),4):\n",
    "    vocab_to_int[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_vocab = {i:word for word,i in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_text_int(texts):\n",
    "    int_list = []\n",
    "    for text in texts:\n",
    "        word_ints = []\n",
    "        for word in text.split():\n",
    "            if word in vocab_to_int:\n",
    "                word_ints.append(vocab_to_int[word])\n",
    "            else:\n",
    "                word_ints.append(vocab_to_int[\"<UNK>\"])\n",
    "        int_list.append(word_ints)\n",
    "    return int_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " delight  says it all\n",
      "[48751, 55192, 7566, 34070]\n"
     ]
    }
   ],
   "source": [
    "summary_int = convert_text_int(clean_summary)\n",
    "print(clean_summary[2])\n",
    "print(summary_int[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these chips are addictive \n",
      "[50906, 16491, 4098, 56250]\n"
     ]
    }
   ],
   "source": [
    "print(clean_summary[713])\n",
    "print(summary_int[713])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_int = convert_text_int(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love  and use the empty containers for medicine advil in my purse  desk  suitcase  also line with felt to keep earrings  perfect little size to disguise small valuables when traveling and love the mints  tiny and powerful without burning my mouth \n",
      "[43923, 9028, 25752, 51565, 37515, 46647, 18540, 40405, 58764, 40248, 2555, 31965, 22875, 49243, 10690, 16755, 51368, 45174, 23204, 7940, 54857, 54746, 27269, 8711, 20535, 7940, 17739, 23437, 17499, 40305, 50181, 25752, 9028, 37515, 16415, 24552, 25752, 31476, 18910, 27745, 31965, 8130]\n"
     ]
    }
   ],
   "source": [
    "print(clean_text[201])\n",
    "print(text_int[201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59217\n"
     ]
    }
   ],
   "source": [
    "# Need to use 300 for embedding dimensions to match CN's vectors.\n",
    "embedding_dim = 300\n",
    "nb_words = len(vocab_to_int)\n",
    "\n",
    "# Create matrix with default values of zero\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings:\n",
    "        word_embedding_matrix[i] = embeddings[word]\n",
    "    else:\n",
    "        # If word not in CN, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding\n",
    "\n",
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(word_embedding_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    input_ = tf.placeholder(dtype=tf.int32,shape=(None,None),name=\"input\")\n",
    "    target = tf.placeholder(dtype=tf.int32,shape=(None,None),name = \"target\")\n",
    "    keep_prob = tf.placeholder(dtype=tf.float32,name=\"keep_prob\")\n",
    "    learning_rate = tf.placeholder(dtype=tf.float32,name=\"learning_rate\")\n",
    "    \n",
    "    #for encoder decoder\n",
    "    source_sequence_length = tf.placeholder(dtype=tf.int32,shape=(None,),name=\"source_sequence_length\")\n",
    "    target_sequence_length = tf.placeholder(dtype=tf.int32,shape=(None,),name=\"target_sequence_length\")\n",
    "    max_target_length = tf.reduce_max(target_sequence_length,name=\"max_target_length\")\n",
    "    return input_,target,keep_prob,learning_rate,source_sequence_length,target_sequence_length,max_target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process decoder input\n",
    "def process_decoder_input(target_data,vocab_to_int,batch_size):\n",
    "    \n",
    "    strided_target = tf.strided_slice(target_data,(0,0),(batch_size,-1),(1,1))\n",
    "    go = tf.fill(value=vocab_to_int[\"<GO>\"],dims=(batch_size,1))\n",
    "    decoder_input = tf.concat((go,strided_target),axis=1)\n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create LSTM cells\n",
    "def get_lstm(rnn_size,keep_prob=0.7):\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm,input_keep_prob=keep_prob)\n",
    "    return drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoding_layer(embeded_rnn_input,rnn_size,keep_prob,num_layers,batch_size,source_sequence_length):\n",
    "#     forward lstm layer\n",
    "    cell_fw = tf.contrib.rnn.MultiRNNCell([get_lstm(rnn_size,keepProb) for _ in range(num_layers)])\n",
    "    cell_fw.zero_state(batch_size)\n",
    "#     backward lstm layer\n",
    "    cell_bw = tf.contrib.rnn.MultiRNNCell([get_lstm(rnn_size,keepProb) for _ in range(num_layers)])\n",
    "    cell_bw.zero_state(batch_size)\n",
    "    \n",
    "    output,output_states = tf.nn.bidirectional_dynamic_rnn(cell_fw=cell_fw,cell_bw=cell_bw,inputs=embeded_rnn_input,\n",
    "                                    sequence_length=source_sequence_length)\n",
    "    \n",
    "    output=tf.concat(output,axis=2)\n",
    "    return output,output_states\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_decoder(embeded_rnn_input,target_sequence_length,decoder_cell,encoder_state,\n",
    "                     output_layer,max_target_length):\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(embeded_rnn_input,target_sequence_length)\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell,helper,initial_state=encoder_state,\n",
    "                                              output_layer=output_layer)\n",
    "    final_outputs, final_state = tf.contrib.seq2seq.dynamic_decode(decoder,impute_finished=True,\n",
    "                                                     maximum_iterations=max_target_length)\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_decoder(embed_rnn_input,embedding_rnn_input,target_sequence_length,decoder_cell,encoder_state,\n",
    "                     output_layer,max_target_length,batch_size):\n",
    "    \n",
    "    start_tokens = tf.tile(tf.constant(dtype=tf.int32,value=[vocab_to_int[\"<GO>\"]]),multiples=[batch_size],name=\"start_tokens\")\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding_rnn_input,\n",
    "                                                      start_tokens=start_tokens,\n",
    "                                                      end_token=vocab_to_int[\"<EOS>\"])\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell,helper,initial_state=encoder_state,\n",
    "                                              output_layer=output_layer)\n",
    "    final_output, final_state = tf.contrib.seq2seq.dynamic_decode(decoder,impute_finished=True,\n",
    "                                                     maximum_iterations=max_target_length)\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer(target_inputs,target_sequence_length,encoder_state,max_target_length,batch_size,num_layers,\n",
    "                   rnn_size):\n",
    "    \n",
    "    vocab_len = len(vocab_to_int)\n",
    "    lstm_cell = tf.contrib.rnn.MultiRNNCell([get_lstm(rnn_size) for _ in range(num_layers)])\n",
    "    output_layer = tf.layers.dense(vocab_len,kernel_initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "\n",
    "    embedding = word_embedding_matrix\n",
    "    embed = tf.nn.embedding_lookup(embedding,target_inputs)\n",
    "    \n",
    "    with tf.variable_scope(\"decoding\"):\n",
    "        train_decode_output = training_decoder(embed,target_sequence_length,lstm_cell,\n",
    "                                                                  encoder_state,output_layer,max_target_length)\n",
    "        \n",
    "    with tf.variable_scope(\"decoding\",reuse=True):\n",
    "        infer_decode_output = inference_decoder(embedding,target_sequence_length,lstm_cell,encoder_state,\n",
    "                                                output_layer,max_target_length,batch_size)\n",
    "    \n",
    "    \n",
    "    return train_decode_output,infer_decode_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_model(source_input,target_input,rnn_size,keep_prob,num_layers,batch_size,source_sequence_length,\n",
    "                  target_sequence_length,max_target_length):\n",
    "    \n",
    "    embedding = word_embedding_matrix\n",
    "    input_embed = tf.nn.embedding_lookup(embedding,source_input) \n",
    "    \n",
    "    encoder_output,encoder_states = encoding_layer(input_embed,rnn_size,keep_prob,num_layers,batch_size,\n",
    "                                                   source_sequence_length)\n",
    "    \n",
    "    output_embed = tf.nn.embedding_lookup(embedding,target_input)\n",
    "    \n",
    "    decoder_train_output, decoder_infer_output = decoding_layer(target_input, target_sequence_length, \n",
    "                                                                encoder_state, max_target_length, batch_size, \n",
    "                                                                num_layers, rnn_size)\n",
    "    return decoder_train_output, decoder_infer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Padding batches\n",
    "def pad_sentence_batch(sentence_batch):\n",
    "    max_length = max([len(sent) for sent in sentence_batch])\n",
    "    print(max_length)\n",
    "    padded_sentences = []\n",
    "    for sent in sentence_batch:\n",
    "        sent_len = len(sent)\n",
    "        if len(sent) < max_length:\n",
    "            padded_sentences.append(sent + [vocab_to_int[\"<PAD>\"] for _ in range(max_length - sent_len)])\n",
    "        else:\n",
    "            padded_sentences.append(sent)\n",
    "    return padded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[[43923, 9028, 25752, 51565, 37515, 46647, 18540, 1, 1, 1, 1], [43923, 9028, 25752, 51565, 37515, 46647, 18540, 9028, 25752, 51565, 37515]]\n"
     ]
    }
   ],
   "source": [
    "sent= [[43923, 9028, 25752, 51565, 37515, 46647, 18540],\n",
    "      [43923, 9028, 25752, 51565, 37515, 46647, 18540, 9028, 25752, 51565, 37515]]\n",
    "\n",
    "print(pad_sentence_batch(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Batches\n",
    "from operator import itemgetter\n",
    "\n",
    "#sort the text from smallest to longest text\n",
    "text_len_sorted= [(i,len(text)) for i,text in enumerate(text_int)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "853"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_int[494051])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_text_len = sorted(text_len_sorted,key= lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_text_int = [text_int[i] for i,j in sorted_text_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these chips are addictive '"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_summary[713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(713, 0),\n",
       " (835, 0),\n",
       " (1059, 0),\n",
       " (1345, 0),\n",
       " (2032, 0),\n",
       " (2304, 0),\n",
       " (2508, 0),\n",
       " (2663, 0),\n",
       " (2680, 0),\n",
       " (2781, 0),\n",
       " (2888, 0),\n",
       " (3888, 0),\n",
       " (4466, 0),\n",
       " (4627, 0),\n",
       " (4696, 0),\n",
       " (5011, 0),\n",
       " (5031, 0),\n",
       " (5615, 0),\n",
       " (5845, 0),\n",
       " (6339, 0),\n",
       " (7025, 0),\n",
       " (7164, 0),\n",
       " (7336, 0),\n",
       " (7461, 0),\n",
       " (7507, 0),\n",
       " (10093, 0),\n",
       " (10494, 0),\n",
       " (10534, 0),\n",
       " (10762, 0),\n",
       " (11060, 0),\n",
       " (12216, 0),\n",
       " (12258, 0),\n",
       " (12461, 0),\n",
       " (13200, 0),\n",
       " (14660, 0),\n",
       " (14868, 0),\n",
       " (14919, 0),\n",
       " (15118, 0),\n",
       " (15691, 0),\n",
       " (15955, 0),\n",
       " (16418, 0),\n",
       " (16775, 0),\n",
       " (16852, 0),\n",
       " (16918, 0),\n",
       " (17341, 0),\n",
       " (18375, 0),\n",
       " (18525, 0),\n",
       " (20882, 0),\n",
       " (21012, 0),\n",
       " (21280, 0),\n",
       " (21470, 0),\n",
       " (21865, 0),\n",
       " (21882, 0),\n",
       " (22687, 0),\n",
       " (22701, 0),\n",
       " (23576, 0),\n",
       " (24569, 0),\n",
       " (24777, 0),\n",
       " (24780, 0),\n",
       " (24913, 0),\n",
       " (25576, 0),\n",
       " (25616, 0),\n",
       " (26309, 0),\n",
       " (27215, 0),\n",
       " (27727, 0),\n",
       " (28176, 0),\n",
       " (28479, 0),\n",
       " (28496, 0),\n",
       " (29036, 0),\n",
       " (29114, 0),\n",
       " (29536, 0),\n",
       " (29943, 0),\n",
       " (30020, 0),\n",
       " (30077, 0),\n",
       " (30079, 0),\n",
       " (30130, 0),\n",
       " (30197, 0),\n",
       " (30429, 0),\n",
       " (30520, 0),\n",
       " (31319, 0),\n",
       " (31974, 0),\n",
       " (32089, 0),\n",
       " (32227, 0),\n",
       " (32403, 0),\n",
       " (32445, 0),\n",
       " (32678, 0),\n",
       " (32789, 0),\n",
       " (32953, 0),\n",
       " (33099, 0),\n",
       " (34611, 0),\n",
       " (35130, 0),\n",
       " (35546, 0),\n",
       " (36003, 0),\n",
       " (37508, 0),\n",
       " (37640, 0),\n",
       " (37821, 0),\n",
       " (38045, 0),\n",
       " (38413, 0),\n",
       " (38905, 0),\n",
       " (39673, 0),\n",
       " (40136, 0),\n",
       " (40411, 0),\n",
       " (40832, 0),\n",
       " (40837, 0),\n",
       " (41043, 0),\n",
       " (41129, 0),\n",
       " (41499, 0),\n",
       " (41604, 0),\n",
       " (41646, 0),\n",
       " (42531, 0),\n",
       " (42616, 0),\n",
       " (43148, 0),\n",
       " (43918, 0),\n",
       " (43924, 0),\n",
       " (44972, 0),\n",
       " (45106, 0),\n",
       " (45110, 0),\n",
       " (45178, 0),\n",
       " (45478, 0),\n",
       " (45827, 0),\n",
       " (46101, 0),\n",
       " (46109, 0),\n",
       " (46637, 0),\n",
       " (46976, 0),\n",
       " (47217, 0),\n",
       " (47389, 0),\n",
       " (47912, 0),\n",
       " (48525, 0),\n",
       " (48688, 0),\n",
       " (49453, 0),\n",
       " (49568, 0),\n",
       " (49576, 0),\n",
       " (49733, 0),\n",
       " (50893, 0),\n",
       " (51074, 0),\n",
       " (51141, 0),\n",
       " (51793, 0),\n",
       " (52316, 0),\n",
       " (52899, 0),\n",
       " (53095, 0),\n",
       " (53159, 0),\n",
       " (53526, 0),\n",
       " (53729, 0),\n",
       " (54261, 0),\n",
       " (54350, 0),\n",
       " (54471, 0),\n",
       " (55099, 0),\n",
       " (55199, 0),\n",
       " (55212, 0),\n",
       " (55840, 0),\n",
       " (55842, 0),\n",
       " (56299, 0),\n",
       " (56760, 0),\n",
       " (56870, 0),\n",
       " (57233, 0),\n",
       " (57768, 0),\n",
       " (57800, 0),\n",
       " (57849, 0),\n",
       " (58248, 0),\n",
       " (58282, 0),\n",
       " (58562, 0),\n",
       " (58665, 0),\n",
       " (58796, 0),\n",
       " (59174, 0),\n",
       " (59785, 0),\n",
       " (59792, 0),\n",
       " (60107, 0),\n",
       " (60177, 0),\n",
       " (60552, 0),\n",
       " (60648, 0),\n",
       " (60664, 0),\n",
       " (61194, 0),\n",
       " (61240, 0),\n",
       " (61436, 0),\n",
       " (61444, 0),\n",
       " (61625, 0),\n",
       " (61633, 0),\n",
       " (61806, 0),\n",
       " (61932, 0),\n",
       " (62943, 0),\n",
       " (62995, 0),\n",
       " (63062, 0),\n",
       " (63176, 0),\n",
       " (63988, 0),\n",
       " (64732, 0),\n",
       " (64770, 0),\n",
       " (64847, 0),\n",
       " (65321, 0),\n",
       " (66198, 0),\n",
       " (67361, 0),\n",
       " (68161, 0),\n",
       " (68845, 0),\n",
       " (69119, 0),\n",
       " (69143, 0),\n",
       " (69433, 0),\n",
       " (69934, 0),\n",
       " (70521, 0),\n",
       " (70959, 0),\n",
       " (72234, 0),\n",
       " (73165, 0),\n",
       " (73729, 0),\n",
       " (74659, 0),\n",
       " (74927, 0),\n",
       " (75117, 0),\n",
       " (76463, 0),\n",
       " (77589, 0),\n",
       " (80004, 0),\n",
       " (80662, 0),\n",
       " (81081, 0),\n",
       " (82240, 0),\n",
       " (84172, 0),\n",
       " (85722, 0),\n",
       " (85753, 0),\n",
       " (85838, 0),\n",
       " (85960, 0),\n",
       " (85992, 0),\n",
       " (86003, 0),\n",
       " (86400, 0),\n",
       " (86543, 0),\n",
       " (86680, 0),\n",
       " (86830, 0),\n",
       " (87688, 0),\n",
       " (89767, 0),\n",
       " (91303, 0),\n",
       " (92380, 0),\n",
       " (93593, 0),\n",
       " (93784, 0),\n",
       " (94175, 0),\n",
       " (94269, 0),\n",
       " (94298, 0),\n",
       " (94798, 0),\n",
       " (95631, 0),\n",
       " (95682, 0),\n",
       " (95796, 0),\n",
       " (97139, 0),\n",
       " (97177, 0),\n",
       " (97653, 0),\n",
       " (97724, 0),\n",
       " (98494, 0),\n",
       " (98518, 0),\n",
       " (98769, 0),\n",
       " (98858, 0),\n",
       " (99533, 0),\n",
       " (99551, 0),\n",
       " (99784, 0),\n",
       " (100241, 0),\n",
       " (100767, 0),\n",
       " (101384, 0),\n",
       " (101729, 0),\n",
       " (101883, 0),\n",
       " (102489, 0),\n",
       " (103159, 0),\n",
       " (103202, 0),\n",
       " (103254, 0),\n",
       " (103647, 0),\n",
       " (103718, 0),\n",
       " (104147, 0),\n",
       " (104172, 0),\n",
       " (104269, 0),\n",
       " (104763, 0),\n",
       " (106015, 0),\n",
       " (106943, 0),\n",
       " (107241, 0),\n",
       " (107641, 0),\n",
       " (108346, 0),\n",
       " (108623, 0),\n",
       " (108642, 0),\n",
       " (108781, 0),\n",
       " (109377, 0),\n",
       " (109561, 0),\n",
       " (110107, 0),\n",
       " (110144, 0),\n",
       " (110553, 0),\n",
       " (110752, 0),\n",
       " (110927, 0),\n",
       " (111667, 0),\n",
       " (112164, 0),\n",
       " (112389, 0),\n",
       " (112464, 0),\n",
       " (113471, 0),\n",
       " (113533, 0),\n",
       " (113540, 0),\n",
       " (113549, 0),\n",
       " (113753, 0),\n",
       " (113804, 0),\n",
       " (114131, 0),\n",
       " (115252, 0),\n",
       " (115352, 0),\n",
       " (115404, 0),\n",
       " (115991, 0),\n",
       " (116195, 0),\n",
       " (116587, 0),\n",
       " (117904, 0),\n",
       " (118376, 0),\n",
       " (118455, 0),\n",
       " (118557, 0),\n",
       " (118561, 0),\n",
       " (118565, 0),\n",
       " (118762, 0),\n",
       " (118777, 0),\n",
       " (118938, 0),\n",
       " (118970, 0),\n",
       " (119292, 0),\n",
       " (119326, 0),\n",
       " (119354, 0),\n",
       " (120592, 0),\n",
       " (120710, 0),\n",
       " (120749, 0),\n",
       " (120778, 0),\n",
       " (121248, 0),\n",
       " (121556, 0),\n",
       " (122560, 0),\n",
       " (122675, 0),\n",
       " (122728, 0),\n",
       " (123010, 0),\n",
       " (123406, 0),\n",
       " (123568, 0),\n",
       " (123581, 0),\n",
       " (123666, 0),\n",
       " (123738, 0),\n",
       " (123926, 0),\n",
       " (124345, 0),\n",
       " (124761, 0),\n",
       " (125898, 0),\n",
       " (126017, 0),\n",
       " (126104, 0),\n",
       " (126255, 0),\n",
       " (126760, 0),\n",
       " (126796, 0),\n",
       " (128435, 0),\n",
       " (128616, 0),\n",
       " (128903, 0),\n",
       " (129534, 0),\n",
       " (129716, 0),\n",
       " (129999, 0),\n",
       " (130039, 0),\n",
       " (130727, 0),\n",
       " (131008, 0),\n",
       " (132506, 0),\n",
       " (133349, 0),\n",
       " (133933, 0),\n",
       " (134307, 0),\n",
       " (135645, 0),\n",
       " (136406, 0),\n",
       " (136505, 0),\n",
       " (136929, 0),\n",
       " (137084, 0),\n",
       " (137279, 0),\n",
       " (137529, 0),\n",
       " (137556, 0),\n",
       " (137701, 0),\n",
       " (137705, 0),\n",
       " (138518, 0),\n",
       " (139326, 0),\n",
       " (139341, 0),\n",
       " (139355, 0),\n",
       " (140023, 0),\n",
       " (140257, 0),\n",
       " (141183, 0),\n",
       " (141510, 0),\n",
       " (142062, 0),\n",
       " (143601, 0),\n",
       " (143714, 0),\n",
       " (143715, 0),\n",
       " (144213, 0),\n",
       " (144279, 0),\n",
       " (144405, 0),\n",
       " (144675, 0),\n",
       " (144854, 0),\n",
       " (145351, 0),\n",
       " (145355, 0),\n",
       " (145418, 0),\n",
       " (145435, 0),\n",
       " (145539, 0),\n",
       " (145745, 0),\n",
       " (145999, 0),\n",
       " (146572, 0),\n",
       " (146619, 0),\n",
       " (147424, 0),\n",
       " (147549, 0),\n",
       " (147655, 0),\n",
       " (148089, 0),\n",
       " (148185, 0),\n",
       " (148561, 0),\n",
       " (148573, 0),\n",
       " (149336, 0),\n",
       " (149393, 0),\n",
       " (149527, 0),\n",
       " (149711, 0),\n",
       " (150626, 0),\n",
       " (150678, 0),\n",
       " (151872, 0),\n",
       " (151875, 0),\n",
       " (152020, 0),\n",
       " (152245, 0),\n",
       " (152692, 0),\n",
       " (152890, 0),\n",
       " (152903, 0),\n",
       " (153071, 0),\n",
       " (153113, 0),\n",
       " (153459, 0),\n",
       " (153643, 0),\n",
       " (154131, 0),\n",
       " (154228, 0),\n",
       " (154470, 0),\n",
       " (154557, 0),\n",
       " (154615, 0),\n",
       " (156104, 0),\n",
       " (156333, 0),\n",
       " (156905, 0),\n",
       " (157385, 0),\n",
       " (157484, 0),\n",
       " (158012, 0),\n",
       " (159329, 0),\n",
       " (160279, 0),\n",
       " (160444, 0),\n",
       " (160550, 0),\n",
       " (160784, 0),\n",
       " (160788, 0),\n",
       " (161062, 0),\n",
       " (161150, 0),\n",
       " (161652, 0),\n",
       " (161973, 0),\n",
       " (162038, 0),\n",
       " (162182, 0),\n",
       " (162924, 0),\n",
       " (163278, 0),\n",
       " (163282, 0),\n",
       " (163674, 0),\n",
       " (164260, 0),\n",
       " (164271, 0),\n",
       " (164414, 0),\n",
       " (164904, 0),\n",
       " (165122, 0),\n",
       " (165897, 0),\n",
       " (165914, 0),\n",
       " (166107, 0),\n",
       " (166670, 0),\n",
       " (166931, 0),\n",
       " (167503, 0),\n",
       " (167796, 0),\n",
       " (168502, 0),\n",
       " (168508, 0),\n",
       " (168667, 0),\n",
       " (168818, 0),\n",
       " (168977, 0),\n",
       " (169148, 0),\n",
       " (169557, 0),\n",
       " (169678, 0),\n",
       " (170047, 0),\n",
       " (170592, 0),\n",
       " (170883, 0),\n",
       " (170950, 0),\n",
       " (171792, 0),\n",
       " (172347, 0),\n",
       " (172525, 0),\n",
       " (174791, 0),\n",
       " (174944, 0),\n",
       " (175147, 0),\n",
       " (176575, 0),\n",
       " (177001, 0),\n",
       " (178025, 0),\n",
       " (178688, 0),\n",
       " (178801, 0),\n",
       " (179220, 0),\n",
       " (179535, 0),\n",
       " (180703, 0),\n",
       " (181826, 0),\n",
       " (182058, 0),\n",
       " (184404, 0),\n",
       " (185050, 0),\n",
       " (186314, 0),\n",
       " (186534, 0),\n",
       " (187075, 0),\n",
       " (187340, 0),\n",
       " (188399, 0),\n",
       " (188620, 0),\n",
       " (188927, 0),\n",
       " (190439, 0),\n",
       " (191271, 0),\n",
       " (191426, 0),\n",
       " (191998, 0),\n",
       " (192287, 0),\n",
       " (192395, 0),\n",
       " (192501, 0),\n",
       " (194845, 0),\n",
       " (195606, 0),\n",
       " (195963, 0),\n",
       " (196022, 0),\n",
       " (197056, 0),\n",
       " (197431, 0),\n",
       " (197550, 0),\n",
       " (197796, 0),\n",
       " (198220, 0),\n",
       " (198978, 0),\n",
       " (199151, 0),\n",
       " (200214, 0),\n",
       " (200852, 0),\n",
       " (201045, 0),\n",
       " (201536, 0),\n",
       " (201951, 0),\n",
       " (201976, 0),\n",
       " (202432, 0),\n",
       " (202660, 0),\n",
       " (202668, 0),\n",
       " (203076, 0),\n",
       " (204255, 0),\n",
       " (204401, 0),\n",
       " (204440, 0),\n",
       " (204453, 0),\n",
       " (204609, 0),\n",
       " (204624, 0),\n",
       " (204892, 0),\n",
       " (204903, 0),\n",
       " (205060, 0),\n",
       " (205198, 0),\n",
       " (205498, 0),\n",
       " (205686, 0),\n",
       " (205903, 0),\n",
       " (206578, 0),\n",
       " (206887, 0),\n",
       " (206901, 0),\n",
       " (207206, 0),\n",
       " (207412, 0),\n",
       " (208337, 0),\n",
       " (208674, 0),\n",
       " (209204, 0),\n",
       " (209514, 0),\n",
       " (209715, 0),\n",
       " (209797, 0),\n",
       " (209911, 0),\n",
       " (209940, 0),\n",
       " (210185, 0),\n",
       " (210255, 0),\n",
       " (210611, 0),\n",
       " (210834, 0),\n",
       " (210984, 0),\n",
       " (211119, 0),\n",
       " (211413, 0),\n",
       " (211829, 0),\n",
       " (212305, 0),\n",
       " (212487, 0),\n",
       " (213152, 0),\n",
       " (213353, 0),\n",
       " (213785, 0),\n",
       " (214068, 0),\n",
       " (214181, 0),\n",
       " (215017, 0),\n",
       " (215379, 0),\n",
       " (215387, 0),\n",
       " (215855, 0),\n",
       " (216376, 0),\n",
       " (216540, 0),\n",
       " (217047, 0),\n",
       " (217080, 0),\n",
       " (217177, 0),\n",
       " (217553, 0),\n",
       " (218133, 0),\n",
       " (218674, 0),\n",
       " (218942, 0),\n",
       " (219057, 0),\n",
       " (219410, 0),\n",
       " (220207, 0),\n",
       " (220562, 0),\n",
       " (220873, 0),\n",
       " (220905, 0),\n",
       " (221293, 0),\n",
       " (221479, 0),\n",
       " (221672, 0),\n",
       " (221872, 0),\n",
       " (222312, 0),\n",
       " (222661, 0),\n",
       " (222973, 0),\n",
       " (223129, 0),\n",
       " (223464, 0),\n",
       " (223859, 0),\n",
       " (224363, 0),\n",
       " (224998, 0),\n",
       " (225446, 0),\n",
       " (225682, 0),\n",
       " (226110, 0),\n",
       " (227914, 0),\n",
       " (228486, 0),\n",
       " (229344, 0),\n",
       " (230357, 0),\n",
       " (230989, 0),\n",
       " (231190, 0),\n",
       " (231216, 0),\n",
       " (231620, 0),\n",
       " (231732, 0),\n",
       " (232365, 0),\n",
       " (232928, 0),\n",
       " (233062, 0),\n",
       " (233367, 0),\n",
       " (233586, 0),\n",
       " (234608, 0),\n",
       " (234625, 0),\n",
       " (235362, 0),\n",
       " (235977, 0),\n",
       " (236030, 0),\n",
       " (237478, 0),\n",
       " (237749, 0),\n",
       " (238053, 0),\n",
       " (238408, 0),\n",
       " (239393, 0),\n",
       " (239766, 0),\n",
       " (240488, 0),\n",
       " (240739, 0),\n",
       " (240837, 0),\n",
       " (240856, 0),\n",
       " (240918, 0),\n",
       " (240931, 0),\n",
       " (240938, 0),\n",
       " (241134, 0),\n",
       " (241315, 0),\n",
       " (241372, 0),\n",
       " (241612, 0),\n",
       " (242204, 0),\n",
       " (242667, 0),\n",
       " (242752, 0),\n",
       " (244189, 0),\n",
       " (244261, 0),\n",
       " (244555, 0),\n",
       " (244917, 0),\n",
       " (245326, 0),\n",
       " (245789, 0),\n",
       " (246164, 0),\n",
       " (246952, 0),\n",
       " (246991, 0),\n",
       " (247763, 0),\n",
       " (248374, 0),\n",
       " (248910, 0),\n",
       " (248914, 0),\n",
       " (250973, 0),\n",
       " (251554, 0),\n",
       " (251657, 0),\n",
       " (252188, 0),\n",
       " (252791, 0),\n",
       " (252991, 0),\n",
       " (253101, 0),\n",
       " (253283, 0),\n",
       " (253837, 0),\n",
       " (254090, 0),\n",
       " (254264, 0),\n",
       " (254343, 0),\n",
       " (255178, 0),\n",
       " (255482, 0),\n",
       " (257930, 0),\n",
       " (258103, 0),\n",
       " (258636, 0),\n",
       " (259448, 0),\n",
       " (259463, 0),\n",
       " (259870, 0),\n",
       " (260037, 0),\n",
       " (260143, 0),\n",
       " (260211, 0),\n",
       " (260358, 0),\n",
       " (260360, 0),\n",
       " (260469, 0),\n",
       " (261067, 0),\n",
       " (261599, 0),\n",
       " (261987, 0),\n",
       " (262044, 0),\n",
       " (262484, 0),\n",
       " (262935, 0),\n",
       " (263377, 0),\n",
       " (263474, 0),\n",
       " (263482, 0),\n",
       " (263815, 0),\n",
       " (263893, 0),\n",
       " (264673, 0),\n",
       " (265173, 0),\n",
       " (265220, 0),\n",
       " (265478, 0),\n",
       " (265709, 0),\n",
       " (266802, 0),\n",
       " (267126, 0),\n",
       " (267654, 0),\n",
       " (268629, 0),\n",
       " (269257, 0),\n",
       " (269401, 0),\n",
       " (270057, 0),\n",
       " (271035, 0),\n",
       " (271099, 0),\n",
       " (271203, 0),\n",
       " (271216, 0),\n",
       " (271785, 0),\n",
       " (271787, 0),\n",
       " (272347, 0),\n",
       " (272623, 0),\n",
       " (272862, 0),\n",
       " (272978, 0),\n",
       " (273084, 0),\n",
       " (273543, 0),\n",
       " (273949, 0),\n",
       " (274426, 0),\n",
       " (274526, 0),\n",
       " (275264, 0),\n",
       " (276170, 0),\n",
       " (276740, 0),\n",
       " (277029, 0),\n",
       " (278386, 0),\n",
       " (278817, 0),\n",
       " (279376, 0),\n",
       " (280577, 0),\n",
       " (280617, 0),\n",
       " (281300, 0),\n",
       " (281316, 0),\n",
       " (281385, 0),\n",
       " (281510, 0),\n",
       " (281887, 0),\n",
       " (281912, 0),\n",
       " (282104, 0),\n",
       " (282243, 0),\n",
       " (282443, 0),\n",
       " (282444, 0),\n",
       " (282699, 0),\n",
       " (282756, 0),\n",
       " (283556, 0),\n",
       " (284108, 0),\n",
       " (284972, 0),\n",
       " (285120, 0),\n",
       " (285958, 0),\n",
       " (286070, 0),\n",
       " (286254, 0),\n",
       " (286496, 0),\n",
       " (286958, 0),\n",
       " (288008, 0),\n",
       " (288138, 0),\n",
       " (288379, 0),\n",
       " (288403, 0),\n",
       " (288626, 0),\n",
       " (288826, 0),\n",
       " (289223, 0),\n",
       " (290164, 0),\n",
       " (290465, 0),\n",
       " (290657, 0),\n",
       " (292334, 0),\n",
       " (292434, 0),\n",
       " (292559, 0),\n",
       " (292626, 0),\n",
       " (292895, 0),\n",
       " (292940, 0),\n",
       " (293705, 0),\n",
       " (293765, 0),\n",
       " (294219, 0),\n",
       " (294518, 0),\n",
       " (294749, 0),\n",
       " (294775, 0),\n",
       " (295079, 0),\n",
       " (296068, 0),\n",
       " (296568, 0),\n",
       " (296581, 0),\n",
       " (296939, 0),\n",
       " (297097, 0),\n",
       " (297587, 0),\n",
       " (297629, 0),\n",
       " (298108, 0),\n",
       " (298271, 0),\n",
       " (298406, 0),\n",
       " (298512, 0),\n",
       " (298878, 0),\n",
       " (299371, 0),\n",
       " (299876, 0),\n",
       " (300082, 0),\n",
       " (300348, 0),\n",
       " (300712, 0),\n",
       " (301201, 0),\n",
       " (302054, 0),\n",
       " (302361, 0),\n",
       " (302475, 0),\n",
       " (302543, 0),\n",
       " (302661, 0),\n",
       " (302694, 0),\n",
       " (302728, 0),\n",
       " (303965, 0),\n",
       " (304238, 0),\n",
       " (304352, 0),\n",
       " (304368, 0),\n",
       " (305354, 0),\n",
       " (305561, 0),\n",
       " (305663, 0),\n",
       " (306317, 0),\n",
       " (306706, 0),\n",
       " (306831, 0),\n",
       " (306835, 0),\n",
       " (306958, 0),\n",
       " (307272, 0),\n",
       " (307520, 0),\n",
       " (308294, 0),\n",
       " (308299, 0),\n",
       " (308685, 0),\n",
       " (308725, 0),\n",
       " (309584, 0),\n",
       " (309861, 0),\n",
       " (309956, 0),\n",
       " (310168, 0),\n",
       " (310179, 0),\n",
       " (310745, 0),\n",
       " (311598, 0),\n",
       " (311680, 0),\n",
       " (311892, 0),\n",
       " (312014, 0),\n",
       " (312175, 0),\n",
       " (313219, 0),\n",
       " (314439, 0),\n",
       " (314447, 0),\n",
       " (314895, 0),\n",
       " (315049, 0),\n",
       " (315141, 0),\n",
       " (315511, 0),\n",
       " (315553, 0),\n",
       " (315860, 0),\n",
       " (316044, 0),\n",
       " (316128, 0),\n",
       " (316256, 0),\n",
       " (316463, 0),\n",
       " (316865, 0),\n",
       " (317299, 0),\n",
       " (317577, 0),\n",
       " (317653, 0),\n",
       " (318475, 0),\n",
       " (318476, 0),\n",
       " (319047, 0),\n",
       " (319233, 0),\n",
       " (319334, 0),\n",
       " (319596, 0),\n",
       " (319987, 0),\n",
       " (320185, 0),\n",
       " (320405, 0),\n",
       " (320735, 0),\n",
       " (321386, 0),\n",
       " (321563, 0),\n",
       " (321797, 0),\n",
       " (322645, 0),\n",
       " (322883, 0),\n",
       " (322933, 0),\n",
       " (323198, 0),\n",
       " (324689, 0),\n",
       " (324781, 0),\n",
       " (324783, 0),\n",
       " (326694, 0),\n",
       " (327677, 0),\n",
       " (327685, 0),\n",
       " (328376, 0),\n",
       " (329429, 0),\n",
       " (329697, 0),\n",
       " (329887, 0),\n",
       " (330454, 0),\n",
       " (330511, 0),\n",
       " (330562, 0),\n",
       " (330937, 0),\n",
       " (331050, 0),\n",
       " (331132, 0),\n",
       " (331567, 0),\n",
       " (331619, 0),\n",
       " (332513, 0),\n",
       " (332658, 0),\n",
       " (334057, 0),\n",
       " (334122, 0),\n",
       " (334132, 0),\n",
       " (334282, 0),\n",
       " (335024, 0),\n",
       " (335230, 0),\n",
       " (335588, 0),\n",
       " (336042, 0),\n",
       " (336539, 0),\n",
       " (336871, 0),\n",
       " (337216, 0),\n",
       " (337383, 0),\n",
       " (337556, 0),\n",
       " (337897, 0),\n",
       " (338039, 0),\n",
       " (338957, 0),\n",
       " (338996, 0),\n",
       " (339116, 0),\n",
       " (340435, 0),\n",
       " (341174, 0),\n",
       " (341902, 0),\n",
       " (341976, 0),\n",
       " (342002, 0),\n",
       " (342246, 0),\n",
       " (342260, 0),\n",
       " (342672, 0),\n",
       " (343548, 0),\n",
       " (343861, 0),\n",
       " (344035, 0),\n",
       " (344043, 0),\n",
       " (345358, 0),\n",
       " (345443, 0),\n",
       " (345822, 0),\n",
       " (346327, 0),\n",
       " (346371, 0),\n",
       " (346444, 0),\n",
       " (346446, 0),\n",
       " (346460, 0),\n",
       " (346463, 0),\n",
       " (346465, 0),\n",
       " (346470, 0),\n",
       " (346580, 0),\n",
       " (347141, 0),\n",
       " (347149, 0),\n",
       " (347388, 0),\n",
       " (347767, 0),\n",
       " (348072, 0),\n",
       " (348239, 0),\n",
       " (348750, 0),\n",
       " (348891, 0),\n",
       " (349802, 0),\n",
       " (350159, 0),\n",
       " (351225, 0),\n",
       " (351272, 0),\n",
       " (351671, 0),\n",
       " (351739, 0),\n",
       " (351844, 0),\n",
       " (352397, 0),\n",
       " (352733, 0),\n",
       " (355175, 0),\n",
       " (355518, 0),\n",
       " (355786, 0),\n",
       " (355976, 0),\n",
       " (356393, 0),\n",
       " (357345, 0),\n",
       " (357931, 0),\n",
       " (358051, 0),\n",
       " (358648, 0),\n",
       " (359152, 0),\n",
       " (359245, 0),\n",
       " (360278, 0),\n",
       " (361269, 0),\n",
       " (361280, 0),\n",
       " (361494, 0),\n",
       " (362110, 0),\n",
       " (362644, 0),\n",
       " (362741, 0),\n",
       " (363146, 0),\n",
       " (363867, 0),\n",
       " (364234, 0),\n",
       " (364726, 0),\n",
       " (365058, 0),\n",
       " (365252, 0),\n",
       " (365761, 0),\n",
       " (366574, 0),\n",
       " (367335, 0),\n",
       " (368301, 0),\n",
       " (369593, 0),\n",
       " (369996, 0),\n",
       " (370516, 0),\n",
       " (370526, 0),\n",
       " (370701, 0),\n",
       " (371056, 0),\n",
       " (371411, 0),\n",
       " (371485, 0),\n",
       " (371575, 0),\n",
       " (371641, 0),\n",
       " (372374, 0),\n",
       " (372777, 0),\n",
       " (372815, 0),\n",
       " (373508, 0),\n",
       " (373970, 0),\n",
       " (374084, 0),\n",
       " (374422, 0),\n",
       " (374491, 0),\n",
       " (374667, 0),\n",
       " (375254, 0),\n",
       " (375283, 0),\n",
       " (375699, 0),\n",
       " (376345, 0),\n",
       " (376606, 0),\n",
       " (376915, 0),\n",
       " (377042, 0),\n",
       " (378475, 0),\n",
       " (378923, 0),\n",
       " (379085, 0),\n",
       " (379146, 0),\n",
       " (380025, 0),\n",
       " (380351, 0),\n",
       " (380671, 0),\n",
       " (381532, 0),\n",
       " (381804, 0),\n",
       " (381941, 0),\n",
       " (382545, 0),\n",
       " (382946, 0),\n",
       " (383138, 0),\n",
       " (383616, 0),\n",
       " (384444, 0),\n",
       " (384489, 0),\n",
       " (384843, 0),\n",
       " (384881, 0),\n",
       " (386078, 0),\n",
       " (386535, 0),\n",
       " (386556, 0),\n",
       " (386932, 0),\n",
       " (387013, 0),\n",
       " (387741, 0),\n",
       " (388316, 0),\n",
       " (389302, 0),\n",
       " (389648, 0),\n",
       " (390119, 0),\n",
       " (391212, 0),\n",
       " ...]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_text_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "epochs = 3\n",
    "# Batch Size\n",
    "batch_size = 250\n",
    "# RNN Size\n",
    "rnn_size = 100\n",
    "# Number of Layers\n",
    "num_layers = 3\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 200\n",
    "decoding_embedding_size = 200\n",
    "# Learning Rate\n",
    "learning_rate = 0.01\n",
    "# Dropout Keep Probability\n",
    "keep_probability = 0.8\n",
    "display_step = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = 'checkpoints/dev'\n",
    "\n",
    "source_int_text = text_int\n",
    "target_int_text = summary_int\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_Default():\n",
    "    \n",
    "    input_,target,keep_prob,learning_rate,source_sequence_length,target_sequence_length,max_target_length = model_inputs()\n",
    "    seq2seq_graph = seq2seq_model(input_,target,rnn_size,keep_probability,num_layers,batch_size,\n",
    "                                  source_sequence_length,max_target_length)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
